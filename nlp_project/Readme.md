# Классификация комментариев интернет-магазина

([Тетрадка с проектом](https://github.com/Vanarty/Yandex-Projects/blob/main/nlp_project/nlp_project.ipynb))

* Автор проекта - *Иванов Артём Юрьевич*
* vanarty@yandex.ru

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75.

**План выполнения:**

1. Загрузить данные и выполнить их ресемплирование по одному часу.
2. Проанализировать данные.
3. Обучить разные модели.
4. Проверить данные на тестовой выборке и сделать выводы.

Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.

## В ходе работы было выполнено:
1. загружены данные, проведена начальная предобработка (данные проверены на пропуски, аномальные значения, дубликаты);
2. данные предварительно разбиты на обучающую и тестовую выборки;
3. проведен анализ бинарного целевого признака (`токсичность комментария`), выявлен сильный дисбаланс классов;
4. проведена очистка текстов комментариев от лишних небуквенных символов с помощью `регулярных выражений1`;
5. проведена токенизация и лемматизация очищенных текстов с помощью библиотеки **nltk**;
6. тексты преобразованы в векторное представление с помощью **TfidfVectorizer** с **n-граммами от 1 до 2**;
7. обучены с подбором гиперпараметров 3 модели с перекрестной проверкой метрики **F1** на 5 фолдах: **LogisticRegression**, **SGDClassifier**, **LGBMClassifier**. Для баланса классов применен метод перевзвешивания с использованием **sample_weight** в методе **fit**;
8. выбрана лучшая модель по результатам **метрики F1** (модель `логистической регрессии`);
9. лучшая модель оценена на тестовой (отложенной) выборке;
10. сделан вывод и даны рекомендации для возможного улучшения работы.

## Выводы:
Лучшей моделью по метрике **F1** на кросс-валидации признана модель **LogisticRegression** (**F1 на CV - 0.781**, **F1 на тестовой выборке - 0.777**). Качество модели на тестовой выборке подходит под условия Заказчика (**F1 не более 0.75**). Так же, по времени обучения данная модель не сильно отстает от самой быстрой модели **SGDClassifier** .

На тестовой выборке модель **LogisticRegression** довольно хорошо распознает целевой класс, даже с учетом его сильной **миноритарности**. Так как в рамках задачи приоритетней выявлять потенциально негативные комментарии, даже если они не являются таковыми, метрика **recall** со значением **0.786**, что выше чем метрика **precision** со значением **0.769**, важнее и показывает хороший результат прогнозирования модели.

В тестовой выборке из **39 823 записей**, среди **4 047 негативных комментариев** модель `логистической регрессии` смогла верно предсказать **3 182 таких комментария**.   

## Рекомендации:
1. Найти причину наличия одинаковых комментариев с разной разметкой по целевому классу. Уточнить как размечались данные.
2. Наличие странных небуквенных символьных комментариев может указывать на попытку взлома, либо техническую неисправность. 
3. Доработать проект с использованием эмбеддингов (**BERT**).
