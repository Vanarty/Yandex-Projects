# Прогнозирование температуры звезд 

([Тетрадка с проектом]([https://pages.github.com/](https://github.com/Vanarty/Yandex-Projects](https://github.com/Vanarty/Yandex-Projects/blob/main/neural_networks/star_temperature_prediction.ipynb)))

* Автор проекта - *Иванов Артём Юрьевич*
* vanarty@yandex.ru

**Заказчик** - обсерватория **«Небо на ладони»**.

**Задача:** c помощью нейросети определять температуру на поверхности обнаруженных звёзд. Обычно для расчёта температуры учёные пользуются следующими методами:
- Закон смещения Вина.
- Закон Стефана-Больцмана.
- Спектральный анализ.
Каждый из них имеет плюсы и минусы. Обсерватория хочет внедрить технологии машинного обучения для предсказания температуры звёзд, надеясь, что этот метод будет наиболее точным и удобным.
В базе обсерватории есть характеристики уже изученных 240 звёзд.

Заказчику важны:

- удобство метода;
- точность метода;
- метрика **RMSE** не должна превышать **4500**.

  ## Было выполнено:
1. Загрузка данных;
2. Анализ данных (EDA data). Опредение зависимостей признаков и их важности для обучения моделей;
3. Предобработка данных по результатам EDA-анализа. Масштабирование числовых и обработка категориальных признаков.
3. Разбивка данных на обучающую и тестовую выборки;
4. Создание класса для задания архитектуры нейронной сети (подбор скрытых слоев и нейронов, функций активации, сравнение комбинаций). **Бейзлайн модель**;
5. Обучение нейронной сети с построением графика «Факт — Прогноз», где по горизонтальной оси будут отложены условные номера звёзд, а по вертикальной — температура в Кельвинах;
6. Создание решения с перебором параметров нейросети (`«dropout»` и `«batchsize»`);
7. Обучение нейронной сети с построением графика «Факт — Прогноз»;
8. Вывод результатов работы нейронной сети, так же в виде графика или таблицы. Сравнение **Baseline модели** и **модели с подобранными параметрами**. 

  ## Выводы:
  Исходя из сравнения результатов исследования и разработки двух моделей нейронных сетей: бейзлайн и улучшенной (с подбором гиперпараметров и регуляризацией с помощью `Dropout`и `Batchnorm`) можно сделать следующие выводы:
- лучшее качество модели нейронной сети достигнуто без использования методов регуляризации `Dropout`и `Batchnorm`;
- подбор гиперпараметров не привел к улучшению метрики **RMSE**, а даже наоборот немного ухудшил этот показатель на тестовой выборке. Ухудшение можно объяснить использованием во втором случае кросс-валидации на 4-х фолдах и усреднением результатов на дополнительной валидационной выборке. Таким образом качество модели стало более стабильным без риска переобучения, но с немного худшим показателем `RMSE` на тестовой выборке;
- для второй модели **количество эпох** было ограничено **в 250**;
- обе модели показали хорошее качество, но Заказчику рекомендуется к использованию вторая модель, как более устойчивая по качеству с учетом случайно выбранного псевдослучайного состояния при работе с данными и проектировании модели (**параметра RAND_SD**).

  ## Рекомендации:
1. Уточнить у Заказчика: стратифицирована ли выборка по **типу звезд** и как проводился отбор звезд для обучения.
2. Уточнить у Заказчика: допустимые пределы значений для представленных в выборке признаков, чтобы обработать аномальные значения, которые потенциально могут вносить сильные искажения на такой малой выборке.
3. Предложить Заказчику подобрать и использовать более подходящую модель, основанную на деревьях решений, для предсказания на табличных данных: **RandomForest, XGBoost, CatBoost, LightGBM**.
